{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "introductory-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "continent-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_pickle(\"./train.pkl\")\n",
    "train_Y = pd.read_pickle(\"./b.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "solved-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [UK’s response to modern slavery leaving victi...\n",
       "1                                       [this is good]\n",
       "2    [The \"forgotten\" Trump roast: Relive his bruta...\n",
       "3               [Meet the happiest #dog in the world!]\n",
       "4    [Tokyo's subway is shut down amid fears over a...\n",
       "Name: postText, dtype: object"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['postText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "magnetic-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "outer-spain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ‘Inexcusable’ failures in UK’s response to mod...\n",
       "1    Donald Trump Appoints Pro-Life Advocate as Ass...\n",
       "2    The ‘forgotten’ Trump roast: Relive his brutal...\n",
       "3    Meet The Happiest Dog In The World, Maru The H...\n",
       "4    Tokyo's subway is shut down amid fears over an...\n",
       "Name: targetTitle, dtype: object"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['targetTitle'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "standard-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "patient-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "miniature-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, flag=False):\n",
    "#     filtered_words = []\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', '', text)\n",
    "    if flag is True:\n",
    "        filtered_words = [ps.stem(word) for word in text.split(' ') if word not in stopwords.words('english')]\n",
    "        filtered_words = ' '.join(filtered_words)\n",
    "    else:\n",
    "        filtered_words = text\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "unlimited-search",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uk respons modern slaveri leav victim destitut abus go free'"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess(train_X['postText'][0][0])\n",
    "preprocess(train_X['postText'][0][0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "spread-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False\n",
    "postText = list(map(lambda x:preprocess(x[0], flag),train_X['postText']))\n",
    "targetParagraphs = list(map(lambda x:preprocess(x[0], flag),train_X['targetParagraphs']))\n",
    "targetTitle = list(map(lambda x:preprocess(x, flag),train_X['targetTitle']))\n",
    "targetDescription = list(map(lambda x:preprocess(x, flag),train_X['targetDescription']))\n",
    "targetKeywords = list(map(lambda x:preprocess(x, flag),train_X['targetKeywords']))\n",
    "# max_seq_len = max(list(map(lambda x: len(x.split(' ')), postText)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "cleared-subdivision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UKs response to modern slavery leaving victims destitute while abusers go free'"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postText[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "understood-administrator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = 100\n",
    "max_seq_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "noticed-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "postText_train = tokenizer.batch_encode_plus(\n",
    "    postText,\n",
    "    max_length = max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "unlikely-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetParagraphs_train = tokenizer.batch_encode_plus(\n",
    "    targetParagraphs,\n",
    "    max_length = max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "plain-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_len = max(list(map(lambda x: len(x.split(' ')), targetTitle)))\n",
    "targetTitle_train = tokenizer.batch_encode_plus(\n",
    "    targetTitle,\n",
    "    max_length = max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "hawaiian-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_len = max(list(map(lambda x: len(x.split(' ')), targetDescription)))\n",
    "targetDescription_train = tokenizer.batch_encode_plus(\n",
    "    targetDescription,\n",
    "    max_length = max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "undefined-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_len = max(list(map(lambda x: len(x.split(' ')), targetDescription)))\n",
    "targetKeywords_train = tokenizer.batch_encode_plus(\n",
    "    targetKeywords,\n",
    "    max_length = max_seq_len,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "champion-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "designing-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "postText_train = postText_train['input_ids']\n",
    "targetParagraphs_train = targetParagraphs_train['input_ids']\n",
    "targetTitle_train = targetTitle_train['input_ids']\n",
    "targetDescription_train = targetDescription_train['input_ids']\n",
    "targetKeywords_train = targetKeywords_train['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "worth-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(targetTitle_train)\n",
    "len(postText_train[0])\n",
    "# len(targetKeywords_train['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "virgin-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "def embed_cosine(col1,col2):\n",
    "    cos_similaritycol = []\n",
    "    for i in range(len(col1)):\n",
    "        #print(i)\n",
    "        val1 = col1.iloc[i]\n",
    "        val2 = col2.iloc[i]\n",
    "        similarity = 1 - spatial.distance.cosine(val1, val2)\n",
    "        cos_similaritycol.append(similarity)\n",
    "    return cos_similaritycol\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "indirect-nebraska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText</th>\n",
       "      <th>targetParagraphs</th>\n",
       "      <th>targetTitle</th>\n",
       "      <th>targetDescription</th>\n",
       "      <th>targetKeywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 2866, 2015, 3433, 2000, 2715, 8864, 2975...</td>\n",
       "      <td>[101, 5190, 1997, 2715, 8864, 5694, 4033, 4140...</td>\n",
       "      <td>[101, 1999, 10288, 7874, 3085, 15428, 1999, 28...</td>\n",
       "      <td>[101, 1999, 10288, 7874, 3085, 15428, 1999, 19...</td>\n",
       "      <td>[101, 2715, 8864, 2533, 2005, 2147, 1998, 2202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2023, 2003, 2204, 102, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[101, 2343, 6221, 8398, 2038, 2805, 1996, 2157...</td>\n",
       "      <td>[101, 6221, 8398, 16823, 2015, 4013, 15509, 81...</td>\n",
       "      <td>[101, 2343, 6221, 8398, 2038, 2805, 4013, 1550...</td>\n",
       "      <td>[101, 4841, 2142, 2005, 2166, 2852, 11084, 181...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 1996, 6404, 8398, 25043, 2128, 3669, 372...</td>\n",
       "      <td>[101, 2043, 1996, 2860, 16584, 2063, 2160, 113...</td>\n",
       "      <td>[101, 1996, 6404, 8398, 25043, 2128, 3669, 372...</td>\n",
       "      <td>[101, 2343, 8398, 2180, 2102, 2022, 2012, 2023...</td>\n",
       "      <td>[101, 8398, 1059, 16257, 2094, 1059, 16257, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 3113, 1996, 5292, 9397, 10458, 3899, 199...</td>\n",
       "      <td>[101, 23677, 2003, 2763, 2019, 2104, 9153, 185...</td>\n",
       "      <td>[101, 3113, 1996, 5292, 9397, 10458, 3899, 199...</td>\n",
       "      <td>[101, 1996, 3720, 2003, 2055, 26280, 1037, 187...</td>\n",
       "      <td>[101, 26280, 18758, 6077, 25462, 2015, 6519, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 5522, 2015, 10798, 2003, 3844, 2091, 134...</td>\n",
       "      <td>[101, 2028, 1997, 5522, 2015, 2350, 10798, 201...</td>\n",
       "      <td>[101, 5522, 2015, 10798, 2003, 3844, 2091, 134...</td>\n",
       "      <td>[101, 1996, 5741, 8636, 2029, 6354, 2702, 2781...</td>\n",
       "      <td>[101, 5522, 6342, 2497, 14035, 6979, 24475, 26...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            postText  \\\n",
       "0  [101, 2866, 2015, 3433, 2000, 2715, 8864, 2975...   \n",
       "1  [101, 2023, 2003, 2204, 102, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [101, 1996, 6404, 8398, 25043, 2128, 3669, 372...   \n",
       "3  [101, 3113, 1996, 5292, 9397, 10458, 3899, 199...   \n",
       "4  [101, 5522, 2015, 10798, 2003, 3844, 2091, 134...   \n",
       "\n",
       "                                    targetParagraphs  \\\n",
       "0  [101, 5190, 1997, 2715, 8864, 5694, 4033, 4140...   \n",
       "1  [101, 2343, 6221, 8398, 2038, 2805, 1996, 2157...   \n",
       "2  [101, 2043, 1996, 2860, 16584, 2063, 2160, 113...   \n",
       "3  [101, 23677, 2003, 2763, 2019, 2104, 9153, 185...   \n",
       "4  [101, 2028, 1997, 5522, 2015, 2350, 10798, 201...   \n",
       "\n",
       "                                         targetTitle  \\\n",
       "0  [101, 1999, 10288, 7874, 3085, 15428, 1999, 28...   \n",
       "1  [101, 6221, 8398, 16823, 2015, 4013, 15509, 81...   \n",
       "2  [101, 1996, 6404, 8398, 25043, 2128, 3669, 372...   \n",
       "3  [101, 3113, 1996, 5292, 9397, 10458, 3899, 199...   \n",
       "4  [101, 5522, 2015, 10798, 2003, 3844, 2091, 134...   \n",
       "\n",
       "                                   targetDescription  \\\n",
       "0  [101, 1999, 10288, 7874, 3085, 15428, 1999, 19...   \n",
       "1  [101, 2343, 6221, 8398, 2038, 2805, 4013, 1550...   \n",
       "2  [101, 2343, 8398, 2180, 2102, 2022, 2012, 2023...   \n",
       "3  [101, 1996, 3720, 2003, 2055, 26280, 1037, 187...   \n",
       "4  [101, 1996, 5741, 8636, 2029, 6354, 2702, 2781...   \n",
       "\n",
       "                                      targetKeywords  \n",
       "0  [101, 2715, 8864, 2533, 2005, 2147, 1998, 2202...  \n",
       "1  [101, 4841, 2142, 2005, 2166, 2852, 11084, 181...  \n",
       "2  [101, 8398, 1059, 16257, 2094, 1059, 16257, 20...  \n",
       "3  [101, 26280, 18758, 6077, 25462, 2015, 6519, 7...  \n",
       "4  [101, 5522, 6342, 2497, 14035, 6979, 24475, 26...  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'postText' : postText_train,\n",
    "                   'targetParagraphs' : targetParagraphs_train,\n",
    "                   'targetTitle' : targetTitle_train,\n",
    "                   'targetDescription' : targetDescription_train,\n",
    "                   'targetKeywords' : targetKeywords_train\n",
    "                  })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "amazing-basis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(df['targetParagraphs'])\n",
    "len(postText_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "joined-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cos = pd.DataFrame({\n",
    "    'postText_Paragraph_Similarity': embed_cosine(df['postText'], df['targetParagraphs']),\n",
    "    'postText_Title_Similarity': embed_cosine(df['postText'], df['targetTitle']),\n",
    "    'postText_Description_Similarity': embed_cosine(df['postText'], df['targetDescription']),\n",
    "    'postText_keyword_Similarity': embed_cosine(df['postText'], df['targetKeywords']),\n",
    "    'Paragraph_Title_Similarity':embed_cosine(df['targetParagraphs'], df['targetTitle']),\n",
    "    'Paragraph_Description_Similarity':embed_cosine(df['targetParagraphs'], df['targetDescription']),\n",
    "    'Paragraph_targetKeywords_Similarity':embed_cosine(df['targetParagraphs'], df['targetKeywords']),\n",
    "    'targetTitle_targetDescription_Similarity':embed_cosine(df['targetTitle'], df['targetDescription']),\n",
    "    'targetTitle_targetKeywords_Similarity':embed_cosine(df['targetTitle'], df['targetKeywords']),\n",
    "    'targetDescription_targetKeywords_Similarity':embed_cosine(df['targetDescription'], df['targetKeywords'])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "elect-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText_Paragraph_Similarity</th>\n",
       "      <th>postText_Title_Similarity</th>\n",
       "      <th>postText_Description_Similarity</th>\n",
       "      <th>postText_keyword_Similarity</th>\n",
       "      <th>Paragraph_Title_Similarity</th>\n",
       "      <th>Paragraph_Description_Similarity</th>\n",
       "      <th>Paragraph_targetKeywords_Similarity</th>\n",
       "      <th>targetTitle_targetDescription_Similarity</th>\n",
       "      <th>targetTitle_targetKeywords_Similarity</th>\n",
       "      <th>targetDescription_targetKeywords_Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168075</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.187662</td>\n",
       "      <td>0.366641</td>\n",
       "      <td>0.276058</td>\n",
       "      <td>0.302270</td>\n",
       "      <td>0.177571</td>\n",
       "      <td>0.657753</td>\n",
       "      <td>0.295508</td>\n",
       "      <td>0.218742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.235074</td>\n",
       "      <td>0.640069</td>\n",
       "      <td>0.287657</td>\n",
       "      <td>0.116352</td>\n",
       "      <td>0.440888</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>0.682510</td>\n",
       "      <td>0.503993</td>\n",
       "      <td>0.438640</td>\n",
       "      <td>0.558571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507935</td>\n",
       "      <td>0.201544</td>\n",
       "      <td>0.275484</td>\n",
       "      <td>0.204334</td>\n",
       "      <td>0.475822</td>\n",
       "      <td>0.507935</td>\n",
       "      <td>0.201544</td>\n",
       "      <td>0.318245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204898</td>\n",
       "      <td>0.370119</td>\n",
       "      <td>0.431550</td>\n",
       "      <td>0.636495</td>\n",
       "      <td>0.384408</td>\n",
       "      <td>0.216762</td>\n",
       "      <td>0.310370</td>\n",
       "      <td>0.451149</td>\n",
       "      <td>0.234416</td>\n",
       "      <td>0.183145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.503692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.485661</td>\n",
       "      <td>0.625910</td>\n",
       "      <td>0.503692</td>\n",
       "      <td>0.619083</td>\n",
       "      <td>0.547978</td>\n",
       "      <td>0.485661</td>\n",
       "      <td>0.625910</td>\n",
       "      <td>0.326155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postText_Paragraph_Similarity  postText_Title_Similarity  \\\n",
       "0                       0.168075                   0.253600   \n",
       "1                       0.235074                   0.640069   \n",
       "2                       0.275484                   1.000000   \n",
       "3                       0.204898                   0.370119   \n",
       "4                       0.503692                   1.000000   \n",
       "\n",
       "   postText_Description_Similarity  postText_keyword_Similarity  \\\n",
       "0                         0.187662                     0.366641   \n",
       "1                         0.287657                     0.116352   \n",
       "2                         0.507935                     0.201544   \n",
       "3                         0.431550                     0.636495   \n",
       "4                         0.485661                     0.625910   \n",
       "\n",
       "   Paragraph_Title_Similarity  Paragraph_Description_Similarity  \\\n",
       "0                    0.276058                          0.302270   \n",
       "1                    0.440888                          0.697394   \n",
       "2                    0.275484                          0.204334   \n",
       "3                    0.384408                          0.216762   \n",
       "4                    0.503692                          0.619083   \n",
       "\n",
       "   Paragraph_targetKeywords_Similarity  \\\n",
       "0                             0.177571   \n",
       "1                             0.682510   \n",
       "2                             0.475822   \n",
       "3                             0.310370   \n",
       "4                             0.547978   \n",
       "\n",
       "   targetTitle_targetDescription_Similarity  \\\n",
       "0                                  0.657753   \n",
       "1                                  0.503993   \n",
       "2                                  0.507935   \n",
       "3                                  0.451149   \n",
       "4                                  0.485661   \n",
       "\n",
       "   targetTitle_targetKeywords_Similarity  \\\n",
       "0                               0.295508   \n",
       "1                               0.438640   \n",
       "2                               0.201544   \n",
       "3                               0.234416   \n",
       "4                               0.625910   \n",
       "\n",
       "   targetDescription_targetKeywords_Similarity  \n",
       "0                                     0.218742  \n",
       "1                                     0.558571  \n",
       "2                                     0.318245  \n",
       "3                                     0.183145  \n",
       "4                                     0.326155  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-merchandise",
   "metadata": {},
   "source": [
    "## For classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "under-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "military-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.head()\n",
    "y = train_Y['truthClass']\n",
    "y.replace(('no-clickbait', 'clickbait'), (0, 1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "directed-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=1)\n",
    "sss.get_n_splits(df_cos, y)\n",
    "for train_index, test_index in sss.split(df_cos, y):\n",
    "    \n",
    "    X_train, X_test = df_cos.iloc[train_index], df_cos.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "aggressive-floor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:07:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=50, n_jobs=12, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=1, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbmodel = xgb.XGBClassifier( max_depth=5,learning_rate=0.1,n_estimators=50,random_state=1,objective='binary:logistic')\n",
    "xgbmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "upset-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = xgbmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-monthly",
   "metadata": {},
   "source": [
    "## with removing shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "automated-combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      4434\n",
      "           1       0.33      0.00      0.00      1428\n",
      "\n",
      "    accuracy                           0.76      5862\n",
      "   macro avg       0.54      0.50      0.43      5862\n",
      "weighted avg       0.65      0.76      0.65      5862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-lunch",
   "metadata": {},
   "source": [
    "## without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "material-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86      4434\n",
      "           1       0.33      0.00      0.00      1428\n",
      "\n",
      "    accuracy                           0.76      5862\n",
      "   macro avg       0.54      0.50      0.43      5862\n",
      "weighted avg       0.65      0.76      0.65      5862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "romantic-gregory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.7574583211465341\n",
      "test score: 0.7560559535994541\n"
     ]
    }
   ],
   "source": [
    "print(\"train score:\", xgbmodel.score(X_train, y_train))\n",
    "print(\"test score:\", xgbmodel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "extended-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svr.sav'\n",
    "pickle.dump(xgbmodel, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-architect",
   "metadata": {},
   "source": [
    "## For regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "athletic-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.head()\n",
    "y = train_Y['truthMedian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "demographic-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=1)\n",
    "sss.get_n_splits(df_cos, y)\n",
    "for train_index, test_index in sss.split(df_cos, y):\n",
    "    \n",
    "    X_train, X_test = df_cos.iloc[train_index], df_cos.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "executed-class",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svr',\n",
       "                 SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "emerging-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "metallic-retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.004032122775924796\n",
      "test score: -0.010303779058122409\n"
     ]
    }
   ],
   "source": [
    "print(\"train score:\", regr.score(X_train, y_train))\n",
    "print(\"test score:\", regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "demonstrated-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "def normalized_mean_squared_error(truth, predictions):\n",
    "    norm = skm.mean_squared_error(truth, np.full(len(truth), np.mean(truth)))\n",
    "    return skm.mean_squared_error(truth, predictions) / norm\n",
    "\n",
    "regression_measures = {'Explained variance': skm.explained_variance_score,\n",
    "                       'Mean absolute error': skm.mean_absolute_error,\n",
    "                       'Mean squared error': skm.mean_squared_error,\n",
    "                       'Median absolute error': skm.median_absolute_error,\n",
    "                       'R2 score': skm.r2_score,\n",
    "                       'Normalized mean squared error': normalized_mean_squared_error}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "narrative-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result(key, value):\n",
    "    value = round(value, ndigits=3)##Added by phil\n",
    "    print(key + ': ' + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "loving-secondary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: -0.0\n",
      "Mean absolute error: 0.346\n",
      "Mean squared error: 0.186\n",
      "Median absolute error: 0.201\n",
      "Normalized mean squared error: 1.01\n",
      "R2 score: -0.01\n"
     ]
    }
   ],
   "source": [
    "for name in sorted(regression_measures):\n",
    "        write_result(name,\n",
    "                     regression_measures[name](y_test, y_pred)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "concrete-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'svr.sav'\n",
    "pickle.dump(regr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-disabled",
   "metadata": {},
   "source": [
    "## LIME stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "thorough-genome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting limeNote: you may need to restart the kernel to use updated packages.\n",
      "  Using cached lime-0.2.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: scipy in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from lime) (1.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.12 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from lime) (0.16.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from lime) (3.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from lime) (4.56.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from lime) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from lime) (0.22.2.post1)\n",
      "\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from scikit-image>=0.12->lime) (2.5)\n",
      "Requirement already satisfied: pillow>=4.3.0 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from scikit-image>=0.12->lime) (7.0.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from scikit-image>=0.12->lime) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from matplotlib->lime) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from matplotlib->lime) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from matplotlib->lime) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from matplotlib->lime) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\shrey\\appdata\\roaming\\python\\python38\\site-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\shrey\\anaconda3\\envs\\pytorch-cpu\\lib\\site-packages (from scikit-learn>=0.18->lime) (1.0.1)\n",
      "Installing collected packages: lime\n",
      "Successfully installed lime-0.2.0.1\n"
     ]
    }
   ],
   "source": [
    "# pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "controlling-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "class_names = ['no-clickbait', 'clickbait']\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 83\n",
    "exp = explainer.explain_instance(X_train[idx], c.predict_proba, num_features=6)\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\n",
    "print('True class: %s' % class_names[newsgroups_test.y[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "fantastic-bundle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postText_Paragraph_Similarity</th>\n",
       "      <th>postText_Title_Similarity</th>\n",
       "      <th>postText_Description_Similarity</th>\n",
       "      <th>postText_keyword_Similarity</th>\n",
       "      <th>Paragraph_Title_Similarity</th>\n",
       "      <th>Paragraph_Description_Similarity</th>\n",
       "      <th>Paragraph_targetKeywords_Similarity</th>\n",
       "      <th>targetTitle_targetDescription_Similarity</th>\n",
       "      <th>targetTitle_targetKeywords_Similarity</th>\n",
       "      <th>targetDescription_targetKeywords_Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12143</th>\n",
       "      <td>0.615266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557225</td>\n",
       "      <td>0.281022</td>\n",
       "      <td>0.615266</td>\n",
       "      <td>0.415135</td>\n",
       "      <td>0.580317</td>\n",
       "      <td>0.557225</td>\n",
       "      <td>0.281022</td>\n",
       "      <td>0.159853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11731</th>\n",
       "      <td>0.232824</td>\n",
       "      <td>0.153995</td>\n",
       "      <td>0.558206</td>\n",
       "      <td>0.377146</td>\n",
       "      <td>0.240438</td>\n",
       "      <td>0.264545</td>\n",
       "      <td>0.575264</td>\n",
       "      <td>0.295915</td>\n",
       "      <td>0.221162</td>\n",
       "      <td>0.321712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>0.117497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.373235</td>\n",
       "      <td>0.055293</td>\n",
       "      <td>0.117497</td>\n",
       "      <td>0.147437</td>\n",
       "      <td>0.023730</td>\n",
       "      <td>0.373235</td>\n",
       "      <td>0.055293</td>\n",
       "      <td>0.046211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6676</th>\n",
       "      <td>0.236771</td>\n",
       "      <td>0.313269</td>\n",
       "      <td>0.313269</td>\n",
       "      <td>0.430332</td>\n",
       "      <td>0.183795</td>\n",
       "      <td>0.183795</td>\n",
       "      <td>0.323081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368015</td>\n",
       "      <td>0.368015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16864</th>\n",
       "      <td>0.149397</td>\n",
       "      <td>0.206328</td>\n",
       "      <td>0.206328</td>\n",
       "      <td>0.408917</td>\n",
       "      <td>0.483936</td>\n",
       "      <td>0.483936</td>\n",
       "      <td>0.402922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546224</td>\n",
       "      <td>0.546224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>0.309691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.309691</td>\n",
       "      <td>0.059518</td>\n",
       "      <td>0.309691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346146</td>\n",
       "      <td>0.309691</td>\n",
       "      <td>0.059518</td>\n",
       "      <td>0.346146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18832</th>\n",
       "      <td>0.444726</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>0.812540</td>\n",
       "      <td>0.192351</td>\n",
       "      <td>0.322054</td>\n",
       "      <td>0.534720</td>\n",
       "      <td>0.113796</td>\n",
       "      <td>0.440333</td>\n",
       "      <td>0.218890</td>\n",
       "      <td>0.113772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18884</th>\n",
       "      <td>0.209918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.418189</td>\n",
       "      <td>0.097832</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.538340</td>\n",
       "      <td>0.580317</td>\n",
       "      <td>0.418189</td>\n",
       "      <td>0.097832</td>\n",
       "      <td>0.102819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>0.256056</td>\n",
       "      <td>0.726650</td>\n",
       "      <td>0.290753</td>\n",
       "      <td>0.444153</td>\n",
       "      <td>0.250910</td>\n",
       "      <td>0.300422</td>\n",
       "      <td>0.189003</td>\n",
       "      <td>0.358773</td>\n",
       "      <td>0.297957</td>\n",
       "      <td>0.244233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15608</th>\n",
       "      <td>0.135821</td>\n",
       "      <td>0.303031</td>\n",
       "      <td>0.135821</td>\n",
       "      <td>0.199823</td>\n",
       "      <td>0.432503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.485252</td>\n",
       "      <td>0.432503</td>\n",
       "      <td>0.497525</td>\n",
       "      <td>0.485252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13676 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       postText_Paragraph_Similarity  postText_Title_Similarity  \\\n",
       "12143                       0.615266                   1.000000   \n",
       "11731                       0.232824                   0.153995   \n",
       "3489                        0.117497                   1.000000   \n",
       "6676                        0.236771                   0.313269   \n",
       "16864                       0.149397                   0.206328   \n",
       "...                              ...                        ...   \n",
       "8147                        0.309691                   1.000000   \n",
       "18832                       0.444726                   0.590924   \n",
       "18884                       0.209918                   1.000000   \n",
       "4046                        0.256056                   0.726650   \n",
       "15608                       0.135821                   0.303031   \n",
       "\n",
       "       postText_Description_Similarity  postText_keyword_Similarity  \\\n",
       "12143                         0.557225                     0.281022   \n",
       "11731                         0.558206                     0.377146   \n",
       "3489                          0.373235                     0.055293   \n",
       "6676                          0.313269                     0.430332   \n",
       "16864                         0.206328                     0.408917   \n",
       "...                                ...                          ...   \n",
       "8147                          0.309691                     0.059518   \n",
       "18832                         0.812540                     0.192351   \n",
       "18884                         0.418189                     0.097832   \n",
       "4046                          0.290753                     0.444153   \n",
       "15608                         0.135821                     0.199823   \n",
       "\n",
       "       Paragraph_Title_Similarity  Paragraph_Description_Similarity  \\\n",
       "12143                    0.615266                          0.415135   \n",
       "11731                    0.240438                          0.264545   \n",
       "3489                     0.117497                          0.147437   \n",
       "6676                     0.183795                          0.183795   \n",
       "16864                    0.483936                          0.483936   \n",
       "...                           ...                               ...   \n",
       "8147                     0.309691                          1.000000   \n",
       "18832                    0.322054                          0.534720   \n",
       "18884                    0.209918                          0.538340   \n",
       "4046                     0.250910                          0.300422   \n",
       "15608                    0.432503                          1.000000   \n",
       "\n",
       "       Paragraph_targetKeywords_Similarity  \\\n",
       "12143                             0.580317   \n",
       "11731                             0.575264   \n",
       "3489                              0.023730   \n",
       "6676                              0.323081   \n",
       "16864                             0.402922   \n",
       "...                                    ...   \n",
       "8147                              0.346146   \n",
       "18832                             0.113796   \n",
       "18884                             0.580317   \n",
       "4046                              0.189003   \n",
       "15608                             0.485252   \n",
       "\n",
       "       targetTitle_targetDescription_Similarity  \\\n",
       "12143                                  0.557225   \n",
       "11731                                  0.295915   \n",
       "3489                                   0.373235   \n",
       "6676                                   1.000000   \n",
       "16864                                  1.000000   \n",
       "...                                         ...   \n",
       "8147                                   0.309691   \n",
       "18832                                  0.440333   \n",
       "18884                                  0.418189   \n",
       "4046                                   0.358773   \n",
       "15608                                  0.432503   \n",
       "\n",
       "       targetTitle_targetKeywords_Similarity  \\\n",
       "12143                               0.281022   \n",
       "11731                               0.221162   \n",
       "3489                                0.055293   \n",
       "6676                                0.368015   \n",
       "16864                               0.546224   \n",
       "...                                      ...   \n",
       "8147                                0.059518   \n",
       "18832                               0.218890   \n",
       "18884                               0.097832   \n",
       "4046                                0.297957   \n",
       "15608                               0.497525   \n",
       "\n",
       "       targetDescription_targetKeywords_Similarity  \n",
       "12143                                     0.159853  \n",
       "11731                                     0.321712  \n",
       "3489                                      0.046211  \n",
       "6676                                      0.368015  \n",
       "16864                                     0.546224  \n",
       "...                                            ...  \n",
       "8147                                      0.346146  \n",
       "18832                                     0.113772  \n",
       "18884                                     0.102819  \n",
       "4046                                      0.244233  \n",
       "15608                                     0.485252  \n",
       "\n",
       "[13676 rows x 10 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}